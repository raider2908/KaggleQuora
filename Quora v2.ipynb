{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Record\n",
    "1. LB result of v1 - Your submission scored 0.41897"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import nltk\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import Training Data\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Test Data\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 6), (2345796, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>217243.942418</td>\n",
       "      <td>220955.655337</td>\n",
       "      <td>0.369198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116708.614502</td>\n",
       "      <td>157751.700002</td>\n",
       "      <td>159903.182629</td>\n",
       "      <td>0.482588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101072.250000</td>\n",
       "      <td>74437.500000</td>\n",
       "      <td>74727.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>192182.000000</td>\n",
       "      <td>197052.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>303216.750000</td>\n",
       "      <td>346573.500000</td>\n",
       "      <td>354692.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404289.000000</td>\n",
       "      <td>537932.000000</td>\n",
       "      <td>537933.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id           qid1           qid2   is_duplicate\n",
       "count  404290.000000  404290.000000  404290.000000  404290.000000\n",
       "mean   202144.500000  217243.942418  220955.655337       0.369198\n",
       "std    116708.614502  157751.700002  159903.182629       0.482588\n",
       "min         0.000000       1.000000       2.000000       0.000000\n",
       "25%    101072.250000   74437.500000   74727.000000       0.000000\n",
       "50%    202144.500000  192182.000000  197052.000000       0.000000\n",
       "75%    303216.750000  346573.500000  354692.500000       1.000000\n",
       "max    404289.000000  537932.000000  537933.000000       1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting the count of words in qid1\n",
    "train['qid1_count'] = train[\"question1\"].apply(lambda x : len(str(x).split()))\n",
    "train['qid2_count'] = train[\"question2\"].apply(lambda x : len(str(x).split()))\n",
    "#What is the maximum difference between the length of two 'marked' duplicate questions?\n",
    "train['count12_diff']= train['qid1_count']-train['qid2_count']  \n",
    "train['count12_diff'] = train['count12_diff'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#From Anokas\n",
    "train_qs = pd.Series(train['question1'].tolist() + train['question2'].tolist()).astype(str)\n",
    "test_qs = pd.Series(test['question1'].tolist() + test['question2'].tolist()).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions with question marks: 99.87%\n",
      "Questions with [math] tags: 0.12%\n",
      "Questions with full stops: 6.31%\n",
      "Questions with capitalised first letters: 99.81%\n",
      "Questions with capital letters: 99.95%\n",
      "Questions with numbers: 11.83%\n"
     ]
    }
   ],
   "source": [
    "qmarks = np.mean(train_qs.apply(lambda x: '?' in x))\n",
    "math = np.mean(train_qs.apply(lambda x: '[math]' in x))\n",
    "fullstop = np.mean(train_qs.apply(lambda x: '.' in x))\n",
    "capital_first = np.mean(train_qs.apply(lambda x: x[0].isupper()))\n",
    "capitals = np.mean(train_qs.apply(lambda x: max([y.isupper() for y in x])))\n",
    "numbers = np.mean(train_qs.apply(lambda x: max([y.isdigit() for y in x])))\n",
    "\n",
    "print('Questions with question marks: {:.2f}%'.format(qmarks * 100))\n",
    "print('Questions with [math] tags: {:.2f}%'.format(math * 100))\n",
    "print('Questions with full stops: {:.2f}%'.format(fullstop * 100))\n",
    "print('Questions with capitalised first letters: {:.2f}%'.format(capital_first * 100))\n",
    "print('Questions with capital letters: {:.2f}%'.format(capitals * 100))\n",
    "print('Questions with numbers: {:.2f}%'.format(numbers * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def word_match_share(row):\n",
    "    # Creating dictionaries of each word\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in str(row['question1']).lower().split():\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in str(row['question2']).lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return R\n",
    "\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# train_word_match = df_train.apply(word_match_share, axis=1, raw=True)\n",
    "# plt.hist(train_word_match[df_train['is_duplicate'] == 0], bins=20, normed=True, label='Not Duplicate')\n",
    "# plt.hist(train_word_match[df_train['is_duplicate'] == 1], bins=20, normed=True, alpha=0.7, label='Duplicate')\n",
    "# plt.legend()\n",
    "# plt.title('Label distribution over word_match_share', fontsize=15)\n",
    "# plt.xlabel('word_match_share', fontsize=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating N-grams features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, ngrams\n",
    "\n",
    "# Functions to create n-grams\n",
    "def one_gram(row):\n",
    "    #Storing the data\n",
    "    que1 = str(row['question1'])\n",
    "    que2 = str(row['question2'])\n",
    "    \n",
    "    #Unigrams\n",
    "    one_que1 = [word for word in que1.lower().split() if word not in stops]\n",
    "    one_que2 = [word for word in que2.lower().split() if word not in stops]\n",
    "    #common elements\n",
    "    common_onegram = len(set(one_que1).intersection(set(one_que2)))\n",
    "    #% of common stuff\n",
    "    onegram_pct = float(common_onegram) / max(len(set(one_que1).union(set(one_que2))),1)\n",
    "    return onegram_pct\n",
    "\n",
    "def two_gram(row):\n",
    "    \n",
    "    #Storing the data\n",
    "    que1 = str(row['question1'])\n",
    "    que2 = str(row['question2'])\n",
    "    \n",
    "    #Unigrams\n",
    "    one_que1 = [word for word in que1.lower().split() if word not in stops]\n",
    "    one_que2 = [word for word in que2.lower().split() if word not in stops]\n",
    "    #2 grams\n",
    "    two_que1 = [word for word in ngrams(one_que1, 2)]\n",
    "    two_que2 = [word for word in ngrams(one_que2, 2)]\n",
    "    #common elements\n",
    "    common_twogram = len(set(two_que1).intersection(set(two_que2)))\n",
    "    #% of common stuff\n",
    "    twogram_pct = float(common_twogram)/max(len(set(two_que1).union(set(two_que2))),1)\n",
    "    return twogram_pct\n",
    "\n",
    "def three_gram(row):\n",
    "    #Storing the data\n",
    "    que1 = str(row['question1'])\n",
    "    que2 = str(row['question2'])\n",
    "    \n",
    "    #Unigrams\n",
    "    one_que1 = [word for word in que1.lower().split() if word not in stops]\n",
    "    one_que2 = [word for word in que2.lower().split() if word not in stops]\n",
    "    # 3 grams\n",
    "    three_que1 = [word for word in ngrams(one_que1, 3)]\n",
    "    three_que2 = [word for word in ngrams(one_que2, 3)]\n",
    "    #common elements\n",
    "    common_threegram = len(set(three_que1).intersection(set(three_que2)))\n",
    "    #% of common stuff\n",
    "    threegram_pct = float(common_threegram)/max(len(set(three_que1).union(set(three_que2))),1)\n",
    "    \n",
    "    return threegram_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re, math\n",
    "\n",
    "# Function to get cosine similarity\n",
    "def get_cosine(row):\n",
    "    # Creating dictionaries of each word\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in str(row['question1']).lower().split():\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in str(row['question2']).lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    vec1 = Counter(q1words)\n",
    "    vec2 = Counter(q2words)\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Raw= True makes the code much faster\n",
    "train['onegram_pct'] = train.apply(one_gram, axis=1, raw=True)\n",
    "train['twogram_pct'] = train.apply(two_gram, axis=1, raw=True)\n",
    "train['threegram_pct'] = train.apply(three_gram, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['Cosine'] = train.apply(get_cosine, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying the function to the train dataset\n",
    "train['match_share'] = train.apply(word_match_share, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Applying all the functions to the test data.\n",
    "test['qid1_count'] = test[\"question1\"].apply(lambda x : len(str(x).split()))\n",
    "test['qid2_count'] = test[\"question2\"].apply(lambda x : len(str(x).split()))\n",
    "#What is the maximum difference between the length of two 'marked' duplicate questions?\n",
    "test['count12_diff']= test['qid1_count']-test['qid2_count']  \n",
    "test['count12_diff'] = test['count12_diff'].abs()\n",
    "test['match_share'] = test.apply(word_match_share, axis=1, raw=True)\n",
    "test['onegram_pct'] = test.apply(one_gram, axis=1, raw=True)\n",
    "test['twogram_pct'] = test.apply(two_gram, axis=1, raw=True)\n",
    "test['threegram_pct'] = test.apply(three_gram, axis=1, raw=True)\n",
    "test['Cosine'] = test.apply(get_cosine, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DS Tools\\Anaconda2\\envs\\py35\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing the library\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['qid1_count', 'qid2_count', 'count12_diff','match_share',\n",
    "       'onegram_pct', 'twogram_pct', 'Cosine']\n",
    "\n",
    "#Creating the predictors (X) and the Target Variables(Y) for the test and train data.\n",
    "train_X = train[feature_list]\n",
    "train_Y = train [['is_duplicate']]\n",
    "\n",
    "train_y = xgb.DMatrix(train_Y)\n",
    "train_x = xgb.DMatrix(train_X , label=train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepping the test data.\n",
    "test_X = test[feature_list]\n",
    "test_x = xgb.DMatrix(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Parameters of the model\n",
    "param = {'max_depth':8, 'eta':0.02, 'silent':1, 'objective':'binary:logistic', 'eval_metric':'logloss' }\n",
    "watchlist = [(train_x, 'train'), (test_x, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training the model\n",
    "model =  xgb.train(params= param , dtrain = train_x ,num_boost_round=400, verbose_eval=10   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43875568813036891"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the log-loss, cross entrophy on the train data.\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(train_Y,model.predict(train_x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Model Prediction output\n",
    "preds = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test['is_duplicate'] = preds"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Creating the is_duplicate flag\n",
    "#test['is_duplicate'] = 0\n",
    "#test['is_duplicate'][(test['Preds']> 0.70)] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Exporting the submission data\n",
    "test[['test_id', 'is_duplicate']].to_csv('sub4.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
